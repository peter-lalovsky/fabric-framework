{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd9a170-a35f-49d2-b6a8-a6e1e0269d29",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602ca259-f2a8-4ee6-b700-77b4a66eef1d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "if is_debug: print(\"\\n---------- This notenook name: nb_system_function - Start ----------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9692bafc-20ae-4f04-acd3-13da05dc0107",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "medallion_name   = \"System\"\n",
    "if is_debug: print(f\"medallion_name: {medallion_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce5bb0-b681-4a0f-b7aa-3a0af5cfda5c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Current session info\n",
    "if is_debug: display(ss.getActiveSession())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a45a8d2-399c-44c8-82ab-6ad450534896",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Print debug info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4636c316-0cbd-4b0e-9644-1bde102f3bba",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "if is_debug:\n",
    "    def fn_print_debug_info(\n",
    "        status\n",
    "        , fn_name\n",
    "        , par\n",
    "    ):\n",
    "        body = \"\"\n",
    "        header = f\"----- {status} ----- {fn_name}() (UTC: {dt.datetime.now()}) - Start -----\"\n",
    "        for k, v in par.items(): body += f\"{k}: {str(v)}<br />\"\n",
    "        footer = f\"----- {status} ----- {fn_name} - End -----\"\n",
    "\n",
    "        if status == \"Success\": color = \"14a212\"\n",
    "        if status == \"Warning\": color = \"c18d24\"\n",
    "        if status == \"Danger\": color = \"bf0000\"\n",
    "\n",
    "        html = \"\"\"<style>\n",
    "            #header, #footer {\n",
    "                color: #^color^;\n",
    "                font-family: Consolas, monaco, monospace;\n",
    "                font-size: 14px;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            #body {\n",
    "                font-family: Consolas, monaco, monospace;\n",
    "                font-size: 14px;\n",
    "            }\n",
    "        </style>\"\"\"\n",
    "        html =  html.replace(\"^color^\", color)\n",
    "        html += f\"<div id=\\\"header\\\">{header}</div>\"\n",
    "        html += f\"<div id=\\\"body\\\">{body}</div>\"\n",
    "        html += f\"<div id=\\\"footer\\\">{footer}</div>\"\n",
    "\n",
    "        if status != \"Success\": displayHTML(html)\n",
    "\n",
    "        return (True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603508ea-3a0d-41e5-b3bc-9b1090e7bb4c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Get now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5b0351-685e-4174-968a-7748e09ccf66",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def fn_get_now(format_):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "\n",
    "    try:\n",
    "        tz = pt.timezone(global_parameter.time_zone_nb)\n",
    "\n",
    "        match format_:\n",
    "            case \"datetime\": now = dt.datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "            case \"date\":     now = dt.datetime.now(tz).strftime(\"%Y-%m-%d\")\n",
    "            case \"string\":   now = dt.datetime.now(tz).strftime(\"%Y%m%d_%H%M%S%f\")[:-3]\n",
    "            case \"year\":     now = dt.datetime.now(tz).strftime(\"%Y\")\n",
    "            case \"month\":    now = dt.datetime.now(tz).strftime(\"%m\")\n",
    "            case \"day\":      now = dt.datetime.now(tz).strftime(\"%d\")\n",
    "            case \"hour\":     now = dt.datetime.now(tz).strftime(\"%H\")\n",
    "            case \"minute\":   now = dt.datetime.now(tz).strftime(\"%M\")\n",
    "            case \"second\":   now = dt.datetime.now(tz).strftime(\"%S\")\n",
    "            case _:          now = dt.datetime.now(tz)\n",
    "\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            fn_print_debug_info(\"Success\", fn_name, par)\n",
    "\n",
    "        return (True, now)\n",
    "    except Exception as ex:\n",
    "        ex = str(ex)\n",
    "        \n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            fn_print_debug_info(\"Danger\", fn_name, ex)\n",
    "\n",
    "        #notebookutils.notebook.exit(\"fn_get_now() is not working properly\") ???\n",
    "\n",
    "        return (False, ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d588a0a7-32ce-4b67-bb7e-4b72560310cf",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151b5e1b-07f6-46a1-a00b-b31872a15094",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Create global dataframe pdf_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cff48d-a38c-4b5e-9b62-e8c1a13f4eeb",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "pdf_log = pd.DataFrame({\n",
    "    \"process_timestamp\": pd.Series(dtype = \"str\")\n",
    "    , \"medallion_name\": pd.Series(dtype = \"str\")\n",
    "    , \"source_name\": pd.Series(dtype = \"str\")\n",
    "    , \"locals\": pd.Series(dtype = \"str\")\n",
    "    , \"alert\": pd.Series(dtype = \"str\")\n",
    "    , \"alert_description\": pd.Series(dtype = \"str\")\n",
    "    , \"logged_datetime\": pd.Series(dtype = \"datetime64[ms]\")\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d18cf3-3267-4720-bc68-92204146cd9c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Insert into local log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3361a31b-f571-497d-8f0f-adfe094bc5f1",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def fn_local_log_insert(\n",
    "    process_timestamp\n",
    "    , medallion_name\n",
    "    , source_name\n",
    "    , locals_\n",
    "    , alert\n",
    "    , alert_description\n",
    "):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "    \n",
    "    try:\n",
    "        global pdf_log\n",
    "\n",
    "        logged_datetime = fn_get_now(\"datetime\")[1]\n",
    "\n",
    "        pdf_log_new_row = pd.DataFrame({\n",
    "            \"process_timestamp\": pd.Series(dtype = \"str\")\n",
    "            , \"medallion_name\": pd.Series(dtype = \"str\")\n",
    "            , \"source_name\": pd.Series(dtype = \"str\")\n",
    "            , \"locals\": pd.Series(dtype = \"str\")\n",
    "            , \"alert\": pd.Series(dtype = \"str\")\n",
    "            , \"alert_description\": pd.Series(dtype = \"str\")\n",
    "            , \"logged_datetime\": pd.Series(dtype = \"datetime64[ms]\")\n",
    "        })\n",
    "\n",
    "        data_new_row = {\"process_timestamp\": process_timestamp\n",
    "            , \"medallion_name\": medallion_name\n",
    "            , \"source_name\": source_name\n",
    "            , \"locals\": locals_\n",
    "            , \"alert\": alert\n",
    "            , \"alert_description\": alert_description\n",
    "            , \"logged_datetime\": logged_datetime}\n",
    "\n",
    "        pdf_log_new_row = pd.DataFrame([data_new_row])        \n",
    "        pdf_log_new_row['logged_datetime'] = pdf_log_new_row['logged_datetime'].apply(lambda x: dt.datetime.strptime(x, '%Y-%m-%d %H:%M:%S.%f'))\n",
    "        pdf_log = pd.concat([pdf_log, pdf_log_new_row])\n",
    "\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            fn_print_debug_info(\"Success\", fn_name, par)\n",
    "\n",
    "        return (True, None)\n",
    "    except Exception as ex:\n",
    "        ex = str(ex)\n",
    "\n",
    "        if alert_description == None: alert_description = ex\n",
    "\n",
    "        if is_debug:\n",
    "            par[\"locals\"]    = locals()\n",
    "            fn_print_debug_info(\"Danger\", fn_name, par)\n",
    "\n",
    "        return (False, ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad06d8fa-d771-41f3-903b-db6f373c143f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Insert into table \"lh_log.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df84a00b-6b79-45f5-9737-390888c65898",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def fn_lh_log_log_insert():\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "    \n",
    "    try:\n",
    "        global pdf_log\n",
    "\n",
    "        # Convert to sdf\n",
    "        pdf_log['logged_datetime'] = pd.to_datetime(pdf_log['logged_datetime'], format = \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "        schema = st.StructType([\n",
    "            st.StructField(\"process_timestamp\", st.StringType())\n",
    "            , st.StructField(\"medallion_name\", st.StringType())\n",
    "            , st.StructField(\"source_name\", st.StringType())\n",
    "            , st.StructField(\"locals\", st.StringType())\n",
    "            , st.StructField(\"alert\", st.StringType())\n",
    "            , st.StructField(\"alert_description\", st.StringType())\n",
    "            , st.StructField(\"logged_datetime\", st.TimestampType())\n",
    "        ])\n",
    "        sdf_log = spark.createDataFrame(pdf_log, schema)\n",
    "\n",
    "        # Format column logged_datetime\n",
    "        sdf_log = sdf_log.withColumn(\n",
    "            \"logged_datetime\"\n",
    "            , sf.to_timestamp(\"logged_datetime\", \"yyyy-MM-dd HH:mm:ss.SSS\")\n",
    "        )\n",
    "        \n",
    "        # Append local log to lh_log.log\n",
    "        sdf_log.write.format(\"delta\")\\\n",
    "            .mode(\"append\")\\\n",
    "            .save(f\"{global_parameter.abfs_path_lh_log}/Tables/log\")\n",
    "\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            if \"sdf_log\" in locals(): par[\"sdf_log\"] = sdf_log.show(n = 5)\n",
    "            fn_print_debug_info(\"Success\", fn_name, par)\n",
    "\n",
    "        return (True, None)\n",
    "    except Exception as ex:\n",
    "        ex = str(ex)\n",
    "\n",
    "        if is_debug:\n",
    "            par[\"locals\"]    = locals()\n",
    "            fn_print_debug_info(\"Danger\", fn_name, par)\n",
    "\n",
    "        return (False, ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf086c-5049-4194-bac6-854d506779c2",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## locals() to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49058ce7-5b31-48d7-a735-7e121de88a06",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def fn_locals_to_json(loc):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "    \n",
    "    try:        \n",
    "        if is_debug: print(f\"----- {fn_name} (loop locals()) - Start -----\")\n",
    "        \n",
    "        locals_ = {}        \n",
    "        for key, value in loc.items():\n",
    "            if key != \"locals_\":                \n",
    "                if is_debug:\n",
    "                    print(f\"key: {key} | value: {value} | value (type): {type(value)}\")\n",
    "                    print(f\"---\")\n",
    "\n",
    "                if str(type(value)) in [\n",
    "                    \"<class 'pyspark.sql.dataframe.DataFrame'>\"\n",
    "                    , \"<class 'pyspark.sql.types.StructType'>\"\n",
    "                    , \"<class 'pandas.core.frame.DataFrame'>\"\n",
    "                    , \"<class 'delta.tables.DeltaTable'>\"\n",
    "                    , \"<class 'datetime.datetime'>\"\n",
    "                    , \"<class 'tuple'>\"\n",
    "                    , \"<class 're.Pattern'>\"\n",
    "                    , \"<class 'pyspark.sql.column.Column'>\"\n",
    "                    , \"<class 'pyspark.sql.types.Row'>\"\n",
    "                    , \"<class 'notebookutils.mssparkutils.handlers.fsHandler.FileInfo'>\"\n",
    "                    , \"<class 'list'>\"\n",
    "                    , \"<class 'requests.models.Response'>\"\n",
    "                    , \"<class 'module'>\"\n",
    "                ]:\n",
    "                    value = str(value)\n",
    "                \n",
    "                locals_[key] = value        \n",
    "        locals_ = j.dumps(locals_)\n",
    "\n",
    "        alert = \"Success\"\n",
    "        alert_description = \"\"\n",
    "\n",
    "        if is_debug: print(f\"----- {fn_name} (loop locals()) - End -----\")\n",
    "\n",
    "        return (alert, alert_description, locals_)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description, None)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "        \n",
    "        if alert == \"Danger\":\n",
    "            fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, locals_, alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05247ac2-5b8b-4fd9-8a54-ba8d9afbe6b1",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Insert \"global_parameter\" into local log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859bd37f-813b-4550-8612-56040df69ec2",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def fn_local_log_insert_global_parameter():\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "    \n",
    "    try:\n",
    "        str_global_parameter        = j.dumps(global_parameter.__dict__)\n",
    "        dict_global_parameter       = j.loads(str_global_parameter)\n",
    "        dict_global_parameter_count = len(dict_global_parameter)\n",
    "\n",
    "        alert             = \"Success\"\n",
    "        alert_description = f\"Global parameter (count): {dict_global_parameter_count}\"\n",
    "\n",
    "        # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "        \n",
    "        del str_global_parameter\n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bedc837-ca3e-4cd8-b37c-0a8fc63b8ec2",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Lakehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61557da4-36d4-47ba-8be3-1c3105184666",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Execute PySpark SQL code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41132bb7-4e2e-45f8-90cc-812c25c1fedc",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def fn_execute_spark_sql(sql_code):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "\n",
    "    try:\n",
    "        sdf               = spark.sql(sql_code)\n",
    "        sdf_count         = sdf.count()\n",
    "        alert             = \"Success\"\n",
    "        alert_description = f\"Rows (count): {sdf_count}\"\n",
    "\n",
    "        # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description, sdf, sdf_count)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description, None, None)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            if \"sdf\" in locals() and sdf != None: par[\"sdf\"] = sdf.show(n = 5)\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "\n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57f0eeb-288d-40d0-b265-571f2ba2b188",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6d8e20-3066-407c-92be-9ed98c3f0eca",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Clean up \"lh_log.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d8f39b-594e-4134-aca5-a0b408c86d3a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Depends on fn_execute_spark_sql()\n",
    "\n",
    "def fn_lh_log_log_cleanup(days_to_keep_log):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "\n",
    "    try:\n",
    "        now = fn_get_now(\"date\")[1]\n",
    "        now_str = dt.datetime.strptime(now, \"%Y-%m-%d\")\n",
    "        logged_datetime = now_str - dt.timedelta(days = int(days_to_keep_log))\n",
    "        sql_query = f\"\"\"DELETE FROM delta.`{global_parameter.abfs_path_lh_log}/Tables/log`\n",
    "WHERE logged_datetime < '{str(logged_datetime)}';\"\"\"\n",
    "\n",
    "        rv_execute_spark_sql = fn_execute_spark_sql(sql_query)\n",
    "        alert                = rv_execute_spark_sql[0]\n",
    "        sdf                  = rv_execute_spark_sql[2]\n",
    "        sdf_count            = sdf.collect()[0][0]\n",
    "\n",
    "        alert             = \"Success\"\n",
    "        alert_description = f\"Log deleted before (date): {str(logged_datetime)}; Rows (count): {sdf_count}\"\n",
    "\n",
    "        # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description, sdf_count)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description, None)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            if \"sdf\" in locals(): par[\"sdf\"] = sdf.show(n = 5)\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "        \n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7502d4e-ce6e-495b-8f12-c6e9dbac923e",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# File System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e1de46-f76b-42f7-a9f8-4b8d65fcc29a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Does file exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171e5249-5f86-49ed-927f-417e29271621",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def fn_does_file_exist(\n",
    "    file_name\n",
    "    , dict_parameter\n",
    "):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "\n",
    "    try:\n",
    "        if notebookutils.fs.exists(file_name) == True:\n",
    "            does_file_exist   = True\n",
    "            alert             = \"Success\"\n",
    "            alert_description = f\"File \\\"{file_name}\\\" exists.\"\n",
    "        else:\n",
    "            does_file_exist   = False\n",
    "            alert             = \"Warning\"\n",
    "            alert_description = f\"File \\\"{file_name}\\\" does not exist.\"\n",
    "\n",
    "            # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description, does_file_exist)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description, None)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "        \n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f92b727-f491-4b01-9659-4d4163994d78",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Copy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8e6af1-06b2-4314-b6b6-2e786b31dea1",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def fn_copy_file(\n",
    "    src,\n",
    "    dstn,\n",
    "    dict_parameter\n",
    "):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "\n",
    "    try:\n",
    "        if notebookutils.fs.exists(src) == True:\n",
    "            notebookutils.fs.fastcp(src, dstn, recurse = True)\n",
    "            alert             = \"Success\"\n",
    "            alert_description = f\"File \\\"{src}\\\" is copied successfully.\"\n",
    "        else:\n",
    "            alert             = \"Warning\"\n",
    "            alert_description = f\"File \\\"{src}\\\" does not exist.\"\n",
    "\n",
    "        # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "        \n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0741b87-e3b9-4faa-82ad-ef304b28784b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Delete file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93230941-9fcd-45e6-bf0a-532b270b67d5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def fn_delete_file(\n",
    "    file_name,\n",
    "    dict_parameter\n",
    "):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "\n",
    "    try:\n",
    "        if notebookutils.fs.exists(file_name):\n",
    "            notebookutils.fs.rm(file_name)\n",
    "            alert             = \"Success\"\n",
    "            alert_description = f\"File \\\"{file_name}\\\" is deleted successfully.\"\n",
    "        else:\n",
    "            alert             = \"Warning\"\n",
    "            alert_description = f\"File \\\"{file_name}\\\" does not exist.\"\n",
    "\n",
    "        # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "        \n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38d167d-f15e-4dd3-a65a-4343ab62a064",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Move file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3c764a-7d71-43e9-9a1e-4c145eea5592",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def fn_move_file(\n",
    "    src,\n",
    "    dstn,\n",
    "    dict_parameter\n",
    "):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "\n",
    "    try:        \n",
    "        if notebookutils.fs.exists(src) == True:\n",
    "            if src != dstn:\n",
    "                notebookutils.fs.mv(src, dstn, create_path = True, overwrite = True)\n",
    "                alert             = \"Success\"\n",
    "                alert_description = f\"File \\\"{src}\\\" is moved successfully.\"\n",
    "            else:\n",
    "                alert             = \"Warning\"\n",
    "                alert_description = f\"Source and destination (\\\"{src}\\\") are the same. File not moved.\"            \n",
    "        else:\n",
    "            alert             = \"Warning\"\n",
    "            alert_description = f\"File \\\"{src}\\\" does not exist.\"\n",
    "\n",
    "        # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "        \n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06c33a9-eb5a-494b-ac04-702ff57f8b22",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Delete folder and all the files and folders in this folder recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5c6b0e-2fe8-4f43-837e-a8cb0201dd6f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Delete folder and everything in it\n",
    "def fn_delete_folder(folder_name):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "\n",
    "    try:            \n",
    "        if notebookutils.fs.exists(folder_name):\n",
    "            notebookutils.fs.rm(folder_name, recurse = True)\n",
    "            alert             = \"Success\"\n",
    "            alert_description = f\"Folder \\\"{folder_name}\\\" is deleted successfully.\"\n",
    "        else:\n",
    "            alert             = \"Warning\"\n",
    "            alert_description = f\"Folder \\\"{folder_name}\\\" does not exist.\"\n",
    "\n",
    "        # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "        \n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aea250-1f66-4055-beb3-586be6c16fc0",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Delete all files and folders in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a6a70b-9d24-48b3-a6c9-a4d984ba058c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Doesn't delete the folder itself\n",
    "def fn_delete_all_in_folder(folder_name):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "\n",
    "    try:        \n",
    "        if notebookutils.fs.exists(folder_name):\n",
    "            files = notebookutils.fs.ls(folder_name)\n",
    "            for file_ in files: notebookutils.fs.rm(file_.path, True)\n",
    "\n",
    "            files = str(files)\n",
    "            file_ = \"<Deleted>\"\n",
    "            \n",
    "            alert             = \"Success\"\n",
    "            alert_description = \"\"\n",
    "        else:\n",
    "            alert             = \"Warning\"\n",
    "            alert_description = f\"Folder \\\"{folder_name}\\\" does not exist.\"\n",
    "\n",
    "        # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "        \n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af270c5-960a-4247-992a-4dedd7cd5a8e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## List folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4987a7-e9ad-45b2-93dc-c25fd5ec750e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def fn_list_folder(\n",
    "    folder_name\n",
    "    , dict_parameter\n",
    "):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "\n",
    "    list_file       = []\n",
    "    list_file_count = 0\n",
    "\n",
    "    try:\n",
    "        if notebookutils.fs.exists(folder_name):\n",
    "            list_file = notebookutils.fs.ls(folder_name)\n",
    "            list_file_count = len(list_file)\n",
    "            alert             = \"Success\"\n",
    "            alert_description = f\"List file (count) {list_file_count}\"\n",
    "        else:\n",
    "            alert             = \"Warning\"\n",
    "            alert_description = f\"Folder \\\"{folder_name}\\\" does not exist.\"\n",
    "\n",
    "        # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description, list_file, list_file_count)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description, None, None)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "        \n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843845b1-a0e3-4cf9-83db-dc6cc38222d7",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Dataframe, Temp View"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238bc82d-f9c2-44d8-b9c1-280a732cc365",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Generate dynamic \"StructType\" list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca94f35-5c6a-4ce5-98a0-5c5804a1251c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Return Dynamic Python code to create new dataframe with proper data types\n",
    "# Used to create new delta table\n",
    "def fn_get_struct_type(sdf):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug:\n",
    "        par = {}\n",
    "\n",
    "    try:\n",
    "        schema = \"StructType([\"\n",
    "\n",
    "        for row in sdf.sort(sdf.sequence.asc()).collect():\n",
    "            if row.sequence == 1: comma = \" \"\n",
    "            else: comma = \" , \"\n",
    "\n",
    "            schema += f\"\\n{comma}StructField(\\\"{row.column_name}\\\", {row.data_type}Type())\"\n",
    "\n",
    "        schema += \"\\n])\"\n",
    "        \n",
    "        alert             = \"Success\"\n",
    "        alert_description = f\"\"\n",
    "\n",
    "        # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description, schema)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description, None)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            if \"sdf\" in locals(): par[\"sdf\"] = sdf.show(n = 5)\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "        \n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2b633b-e7a9-44a1-a6de-3a00b35fada2",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Generate select columns for extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b4937-3d49-43cd-a7b3-4d1d2c2f5f81",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Return Dynamic Python code to apply aliases and cast to propre data type\n",
    "# Used to select from dataframe and insert into delta table\n",
    "# Columns renamed with alias and datatypes applied\n",
    "\n",
    "def fn_get_select_column(\n",
    "    sdf_name\n",
    "    , sdf\n",
    "):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug:\n",
    "        par = {}\n",
    "\n",
    "    try:\n",
    "        column = sdf_name + \".select(\"\n",
    "\n",
    "        for row in sdf.sort(sdf.sequence.asc()).collect():\n",
    "            if row.sequence == 1: comma = \"\"\n",
    "            else: comma = \",\"\n",
    "\n",
    "            column += f\"\\n{comma} {sdf_name}[\\\"{row.column_name}\\\"].alias(\\\"{row.alias_name}\\\").cast(st.{row.data_type}Type())\"\n",
    "\n",
    "        column += \")\"\n",
    "\n",
    "        alert             = \"Success\"\n",
    "        alert_description = f\"\"\n",
    "\n",
    "        # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description, column)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description, None)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            if \"sdf\" in locals(): par[\"sdf\"] = sdf.show(n = 5)\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "        \n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec832ab-87e8-49e2-a40d-5e359e68f3d7",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Save SDF in OneLake as table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab821e7c-7731-451a-9c48-0b096f65e784",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def fn_save_sdf_as_table(\n",
    "    sdf\n",
    "    , format_\n",
    "    , mode\n",
    "    , path\n",
    "    , dict_parameter\n",
    "):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "\n",
    "    try:\n",
    "        # If overwrite the table, overwrite the schema too\n",
    "        if mode == \"overwrite\": option = \".option(\\\"overwriteSchema\\\", \\\"True\\\")\"\n",
    "        else:                   option = \"\"\n",
    "\n",
    "        # Set dynamic code\n",
    "        code = f\"sdf.write.format(\\\"{format_}\\\").mode(\\\"{mode}\\\"){option}.save(\\\"{path}\\\")\"\n",
    "\n",
    "        # Create table (execute dynamic code)\n",
    "        eval(code)\n",
    "\n",
    "\n",
    "        # Set \"table_name\"\n",
    "        if dict_parameter[\"technology\"] == \"SQL Server\":\n",
    "            server_name   = dict_parameter[\"server_name_clean\"]\n",
    "            database_name = dict_parameter[\"database_name_clean\"]\n",
    "            schema_name   = dict_parameter[\"schema_name_clean\"]\n",
    "            table_name    = dict_parameter[\"table_name_clean\"]\n",
    "            table         = f\"{server_name}_{database_name}_{schema_name}_{table_name}\"\n",
    "\n",
    "        if dict_parameter[\"technology\"] == \"Lakehouse\":\n",
    "            lakehouse_name = dict_parameter[\"lakehouse_name_clean\"]\n",
    "            table_name     = dict_parameter[\"table_name_clean\"]\n",
    "            table          = f\"{lakehouse_name}.{table_name}\"\n",
    "\n",
    "        if dict_parameter[\"technology\"] == \"Excel\":\n",
    "            technology     = dict_parameter[\"technology_clean\"]\n",
    "            folder_name    = dict_parameter[\"folder_name_clean\"]\n",
    "            file_name      = dict_parameter[\"file_name_clean\"]\n",
    "            worksheet_name = dict_parameter[\"worksheet_name_clean\"]\n",
    "            table          = f\"{technology}_{folder_name}_{file_name}_{worksheet_name}\"\n",
    "\n",
    "        if dict_parameter[\"technology\"] == \"CSV\":\n",
    "            technology     = dict_parameter[\"technology_clean\"]\n",
    "            folder_name    = dict_parameter[\"folder_name_clean\"]\n",
    "            file_name      = dict_parameter[\"file_name_clean\"]\n",
    "            table          = f\"{technology}_{folder_name}_{file_name}\"\n",
    "\n",
    "        if dict_parameter[\"technology\"] == \"JSON\":\n",
    "            technology     = dict_parameter[\"technology_clean\"]\n",
    "            folder_name    = dict_parameter[\"folder_name_clean\"]\n",
    "            file_name      = dict_parameter[\"file_name_clean\"]\n",
    "            table          = f\"{technology}_{folder_name}_{file_name}\"\n",
    "\n",
    "        table = table.replace(\"__\", \"_\")\n",
    "\n",
    "        alert             = \"Success\"\n",
    "        alert_description = f\"Table \\\"{table}\\\" saved successfully.\"\n",
    "\n",
    "        # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "        \n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c16a02-db5b-424c-a229-ef250d87bcce",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Get existing dataframe list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa16cfa-6091-4feb-a0bb-a08430777f9a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Get list of the existing dataframes\n",
    "\n",
    "def fn_get_dataframe_list():\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "\n",
    "    try:\n",
    "        dataframe_list = [k for (k, v) in globals().items() if isinstance(v, df)]\n",
    "        dataframe_list_count = len(dataframe_list)\n",
    "\n",
    "        alert             = \"Success\"\n",
    "        alert_description = f\"Dataframes (count): {dataframe_list_count}\"\n",
    "\n",
    "        # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description, dataframe_list, dataframe_list_count)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description, None, None)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "        \n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ce9f2d-8679-4927-8141-b5f5391d9c7b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Get existing temp view list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df762f81-539f-461e-9ea8-7b5efd4bc4dd",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Get list of the existing dataframes\n",
    "\n",
    "def fn_get_temp_view_list():\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "\n",
    "    try:\n",
    "        view_list = fn_execute_spark_sql(f\"SHOW VIEWS;\")[2]\n",
    "        view_list_count = view_list.count()\n",
    "\n",
    "        alert             = \"Success\"\n",
    "        alert_description = f\"Views (count): {view_list_count}\"\n",
    "\n",
    "        # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description, view_list, view_list_count)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description, None, None)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "        \n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfb2579-9d0c-4bf3-a4d9-3d157759ab68",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# String"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78adea1-a32b-45c7-bf37-0542187a226e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Clean all not alphanumericals in single SDF column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb657fdc-c3e6-4af9-903f-9d0d7d1098a4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def fn_replace_all_not_alphanumericals_in_single_column_in_sdf(\n",
    "    sdf\n",
    "    , col_name\n",
    "    , replace_with\n",
    "):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "\n",
    "    try:\n",
    "        pdf = sdf.toPandas()\n",
    "        pdf = pdf.replace(\n",
    "            to_replace = {col_name: \"\\W+\"},\n",
    "            value      = replace_with,\n",
    "            regex      = True\n",
    "        )\n",
    "        sdf = spark.createDataFrame(pdf)\n",
    "        sdf_count = sdf.count()\n",
    "\n",
    "        alert             = \"Success\"\n",
    "        alert_description = f\"Not alphanumericals in column \\\"{col_name}\\\" successfully replaced with \\\"{replace_with}\\\"\"\n",
    "\n",
    "        # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description, sdf, sdf_count)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description, None, None)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "        \n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73db560c-df3e-4c72-884d-4ac229fbd2cb",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Clean all not alphanumericals in string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a426a01c-c96f-47de-82ff-1f319a6a3c44",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def fn_clean_not_alphanumeric_in_string(\n",
    "    string\n",
    "    , replace_with\n",
    "):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "\n",
    "    try:\n",
    "        reg_ex = re.compile(\"\\W+\")\n",
    "        output = reg_ex.sub(replace_with, string).strip()\n",
    "\n",
    "        alert             = \"Success\"\n",
    "        alert_description = f\"Not alphanumericals in string \\\"{string}\\\" successfully replaced with \\\"{replace_with}\\\"\"\n",
    "\n",
    "        # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description, output)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description, None)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "        \n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668a3d67-a19e-4ae5-8660-467d74bd8394",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Clean accents in SDF column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4883cc2f-16fe-425e-bbef-ce17060ddeae",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Clean accents in single sdf column\n",
    "\n",
    "def fn_clean_accent_in_sdf_column_make_trans():\n",
    "    matching_string = \"\"\n",
    "    replace_string = \"\"\n",
    "\n",
    "    for i in range(ord(\" \"), sys.maxunicode):\n",
    "        name = ucd.name(chr(i), \"\")\n",
    "        if \"WITH\" in name:\n",
    "            try:\n",
    "                base = ucd.lookup(name.split(\" WITH\")[0])\n",
    "                matching_string += chr(i)\n",
    "                replace_string += base\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "    return matching_string, replace_string\n",
    "\n",
    "def fn_clean_accent_in_sdf_column(column_name):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "\n",
    "    try:\n",
    "        matching_string, replace_string = fn_clean_accent_in_sdf_column_make_trans()\n",
    "        \n",
    "        alert             = \"Success\"\n",
    "        alert_description = f\"Accents in column {column_name} are cleaned successfully.\"\n",
    "\n",
    "        output = sf.translate(\n",
    "            sf.regexp_replace(column_name, \"\\p{M}\", \"\")\n",
    "            , matching_string, replace_string\n",
    "        ).alias(column_name)\n",
    "\n",
    "        # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description, output)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description, None)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "        \n",
    "        del matching_string\n",
    "        del replace_string\n",
    "        del output\n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c003aa13-d09b-4132-8e38-6e379b30535e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Clean accents in string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf87a6-ff16-4258-aef2-52b9390364d5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# éèàç --> eeac\n",
    "\n",
    "def fn_clean_accent_in_string(string):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "\n",
    "    try:\n",
    "        output = \"\".join(c for c in ucd.normalize(\"NFD\", string) if ucd.category(c) != \"Mn\")\n",
    "\n",
    "        alert             = \"Success\"\n",
    "        alert_description = f\"Accents in string \\\"{string}\\\" are cleaned successfully.\"\n",
    "\n",
    "        # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description, output)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description, None)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "        \n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a68cc55-e44d-4180-b84b-942f76dc8e7c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Replace in all the collumns in SDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d425ae-6935-4950-843e-0ffeb38e548c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def fn_replace_in_all_columns_in_sdf(\n",
    "    sdf\n",
    "    , replace_what\n",
    "    , replace_with\n",
    "):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "\n",
    "    try:\n",
    "        cols = sdf.columns        \n",
    "        for c in cols:\n",
    "            sdf = sdf.withColumn(\n",
    "                c\n",
    "                , sf.when((sf.col(c) == replace_what), replace_with).otherwise(sf.col(c))\n",
    "            )\n",
    "\n",
    "        sdf_count = sdf.count()\n",
    "\n",
    "        alert             = \"Success\"\n",
    "        alert_description = f\"\\\"{replace_what}\\\" is successfully replaced with \\\"{replace_with}\\\" in all columns.\"\n",
    "\n",
    "        # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description, sdf, sdf_count)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description, None, None)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            if \"sdf\" in locals(): par[\"sdf\"] = sdf.show(n = 5)\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "     \n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62104416-6f8e-4a3d-b5cf-9668bcd2c2ec",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Replace in single collumn in SDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f81e0f6-f00b-4185-807f-5caec5068021",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def fn_replace_in_single_column_in_sdf(\n",
    "    sdf\n",
    "    , column_name\n",
    "    , replace_what\n",
    "    , replace_with\n",
    "):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "\n",
    "    try:\n",
    "        sdf = sdf.withColumn(\n",
    "            column_name\n",
    "            , sf.regexp_replace(sf.col(column_name), replace_what, replace_with)\n",
    "        )\n",
    "\n",
    "        sdf_count = sdf.count()\n",
    "\n",
    "        alert             = \"Success\"\n",
    "        alert_description = f\"\\\"{replace_what}\\\" is successfully replaced with \\\"{replace_with}\\\" in column \\\"{column_name}\\\".\"\n",
    "\n",
    "        # fn_print_debug_info_123(\"Success\", fn_name, par) # test \"except\"\n",
    "\n",
    "        return (alert, alert_description, sdf, sdf_count)\n",
    "    except Exception as ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = str(ex)\n",
    "\n",
    "        return (alert, alert_description, None, None)\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            if \"sdf\" in locals(): par[\"sdf\"] = sdf.show(n = 5)\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "        \n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9a9bf6-be94-4225-81ef-68c462632c66",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0c2679-b76f-499b-bda2-2eb485fa5060",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Mask Bearer Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2134a86f-233c-4868-9b1d-5ec8cc522117",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Mask Bearer Token before insert in log\n",
    "\n",
    "def fn_mask_bearer_token(mask):\n",
    "    # Mask dict_parameter\n",
    "    if str(type(mask)) == \"<class 'dict'>\" and \"headers\" in mask:\n",
    "        headers = mask[\"headers\"]\n",
    "\n",
    "        if \"Authorization\" in headers:\n",
    "            authorization = headers[\"Authorization\"]\n",
    "            bearer = authorization[:7]\n",
    "            authorization = f\"{bearer}[REDACTED]\"\n",
    "            headers.update({\"Authorization\": authorization})\n",
    "            mask.update({\"headers\": headers})\n",
    "    \n",
    "    # Mask request_code\n",
    "    if str(type(mask)) == \"<class 'str'>\":\n",
    "        index = mask.find(\"Bearer \")\n",
    "        if index != -1:            \n",
    "            authorization = mask[index:]\n",
    "            end = authorization.find(\"'\")\n",
    "            replace_what = mask[(index + 7):(end + index)]\n",
    "            mask = mask.replace(replace_what, \"[REDACTED]\")\n",
    "\n",
    "    # Mask headers\n",
    "    if \"Authorization\" in mask:\n",
    "        authorization = mask[\"Authorization\"]\n",
    "        bearer = authorization[:7]\n",
    "        authorization = f\"{bearer}[REDACTED]\"\n",
    "        mask.update({\"Authorization\": authorization})\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98250906-82fe-488d-88b7-11a7b58d98fb",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Execute API request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9be92d-fcb4-403b-ac49-f64434512a9d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# method: GET, POST\n",
    "# response_format: JSON, XML\n",
    "# dict_parameter\n",
    "#  GET\n",
    "#    url     String \"https://api.github.com/events\"\n",
    "#    headers Dict   {\"Content-Type\": \"application/json\", \"User-Agent\": \"zPL Concept\", \"Authorization\": \"Bearer 123\"} # Bearer Token\n",
    "#    params  Dict   {\"id\": 4}\n",
    "#    auth    Tuple  (\"Username\", \"Password\") # Basic\n",
    "#    timeout Int    5\n",
    "#  POST\n",
    "#    url     String \"https://api.github.com/events\"\n",
    "#    headers Dict\t\n",
    "#    data    Dict\n",
    "#    json    Dict\n",
    "#    auth    Tuple\n",
    "#    timeout Int    5\n",
    "\n",
    "def fn_api_request(\n",
    "    method\n",
    "    , response_format\n",
    "    , dict_parameter\n",
    "):\n",
    "    fn_name        = stk()[0][3]\n",
    "    caller_fn_name = stk()[1].function.replace(\"<module>\", \"\")\n",
    "    if is_debug: par = {}\n",
    "\n",
    "    try:\n",
    "        alert = \"Danger\"\n",
    "\n",
    "        arguments = \"\"\n",
    "        for key, val in dict_parameter.items():\n",
    "            if str(type(val)) == \"<class 'str'>\": val = f\"\\\"{val}\\\"\"\n",
    "            arguments += f\"{key} = {val}, \"\n",
    "        arguments = arguments[:-2]\n",
    "        \n",
    "        if   method == \"GET\":    request_code = f\"req.get({arguments})\"\n",
    "        elif method == \"POST\":   request_code = f\"req.post({arguments})\"\n",
    "        elif method == \"DELETE\": request_code = f\"req.delete({arguments})\"\n",
    "\n",
    "        response             = eval(request_code)\n",
    "        is_response_ok       = response.ok\n",
    "        response_status_code = response.status_code\n",
    "        response_reason      = response.reason\n",
    "        response_status      = f\"{response_status_code} ({response_reason}\"\n",
    "        response.raise_for_status()\n",
    "\n",
    "        if is_response_ok:\n",
    "            alert             = \"Success\"\n",
    "            alert_description = f\"Response status: {response_status})\"\n",
    "            if response_format == \"JSON\":     return_value = (f\"{response_status})\", response.json())\n",
    "            if response_format == \"XML\":      return_value = (f\"{response_status})\", response.text)\n",
    "            if response_format == \"Response\": return_value = (f\"{response_status})\", response)\n",
    "        else:    \n",
    "            alert_description = f\"Response status: {response_status}\"\n",
    "\n",
    "        return return_value\n",
    "            \n",
    "    except req.exceptions.HTTPError as http_err:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = f\"{response_status}: HTTP Error)\"\n",
    "        return_value      = (f\"{response_status}: HTTP Error)\", http_err)\n",
    "\n",
    "        return return_value\n",
    "    except req.exceptions.ConnectionError as conn_err:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = f\"{response_status}: Connection Error)\"\n",
    "        return_value      = (f\"{response_status}: Connection Error)\", conn_err)\n",
    "\n",
    "        return return_value\n",
    "    except req.exceptions.Timeout as timeout:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = f\"{response_status}: Timeout)\"\n",
    "        return_value      = (f\"{response_status}: Timeout)\", timeout)\n",
    "\n",
    "        return return_value\n",
    "    except req.exceptions.RequestException as req_ex:\n",
    "        alert             = \"Danger\"\n",
    "        alert_description = f\"{response_status}: Request Exception)\"\n",
    "        return_value      = (f\"{response_status}: Request Exception)\", req_ex)\n",
    "\n",
    "        return return_value\n",
    "    finally:\n",
    "        if is_debug:\n",
    "            par[\"locals\"] = locals()\n",
    "            if \"sdf\" in locals(): par[\"sdf\"] = sdf.show(n = 5)\n",
    "            fn_print_debug_info(alert, fn_name, par)\n",
    "            del par\n",
    "\n",
    "        # Keep only the first element of \"return_value\" in the log\n",
    "        if response_format == \"JSON\":\n",
    "            list_return_value = list(return_value)\n",
    "            list_return_value[1] = list_return_value[1][:1]\n",
    "            return_value = tuple(list_return_value)\n",
    "            del list_return_value\n",
    "\n",
    "        # Keep only the first 1000 characters of \"return_value\" in the log\n",
    "        if response_format == \"XML\":\n",
    "            list_return_value = list(return_value)\n",
    "            list_return_value[1] = f\"{list_return_value[1][:1000]}...\"\n",
    "            return_value = tuple(list_return_value)\n",
    "            del list_return_value\n",
    "\n",
    "        del key\n",
    "        del val\n",
    "        del arguments\n",
    "\n",
    "        # Mask Bearer Token\n",
    "        dict_parameter = fn_mask_bearer_token(dict_parameter)\n",
    "        request_code = fn_mask_bearer_token(request_code)\n",
    "        \n",
    "        fn_local_log_insert(global_parameter.process_timestamp, medallion_name, fn_name, fn_locals_to_json(locals())[2], alert, alert_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e36515-1828-4b4f-85cd-813bd5b8434a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "if is_debug: print(\"\\n---------- This notenook name: nb_system_function - End ----------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
